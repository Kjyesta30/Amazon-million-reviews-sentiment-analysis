{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Project602_SentimentalAnalysis.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IZnMZqaWpEk_",
        "colab_type": "text"
      },
      "source": [
        "## Project\n",
        "### **Performing Sentimental Analysis on reviews from amazon.**\n",
        "The data to use is located here: http://deepyeti.ucsd.edu/jianmo/amazon/categoryFilesSmall/Cell_Phones_and_Accessories_5.json.gz.\n",
        "As it is a gziped json file, I would like to download and extract it directly into colab, this can be done using the following lines:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WW_W7kTrQD7O",
        "colab_type": "code",
        "outputId": "321f8220-31d7-4615-9f5f-48692d0ed541",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "!curl http://deepyeti.ucsd.edu/jianmo/amazon/categoryFilesSmall/Cell_Phones_and_Accessories_5.json.gz -o reviews.json.gz\n",
        "!gunzip reviews.json.gz\n",
        "!ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  161M  100  161M    0     0  10.7M      0  0:00:15  0:00:15 --:--:-- 11.0M\n",
            "y\n",
            "\n",
            "reviews.json  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YnlUB8MGtSeD",
        "colab_type": "text"
      },
      "source": [
        "**Quick look at the Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sn64bNDOQTdX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "data = pd.read_json('reviews.json',lines=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dwOp8ZtjQqrq",
        "colab_type": "code",
        "outputId": "c6afa92b-1f67-4ff7-9cde-912737e49d8b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "data"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>overall</th>\n",
              "      <th>verified</th>\n",
              "      <th>reviewTime</th>\n",
              "      <th>reviewerID</th>\n",
              "      <th>asin</th>\n",
              "      <th>style</th>\n",
              "      <th>reviewerName</th>\n",
              "      <th>reviewText</th>\n",
              "      <th>summary</th>\n",
              "      <th>unixReviewTime</th>\n",
              "      <th>vote</th>\n",
              "      <th>image</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5</td>\n",
              "      <td>True</td>\n",
              "      <td>08 4, 2014</td>\n",
              "      <td>A24E3SXTC62LJI</td>\n",
              "      <td>7508492919</td>\n",
              "      <td>{'Color:': ' Bling'}</td>\n",
              "      <td>Claudia Valdivia</td>\n",
              "      <td>Looks even better in person. Be careful to not...</td>\n",
              "      <td>Can't stop won't stop looking at it</td>\n",
              "      <td>1407110400</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5</td>\n",
              "      <td>True</td>\n",
              "      <td>02 12, 2014</td>\n",
              "      <td>A269FLZCB4GIPV</td>\n",
              "      <td>7508492919</td>\n",
              "      <td>NaN</td>\n",
              "      <td>sarah ponce</td>\n",
              "      <td>When you don't want to spend a whole lot of ca...</td>\n",
              "      <td>1</td>\n",
              "      <td>1392163200</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>True</td>\n",
              "      <td>02 8, 2014</td>\n",
              "      <td>AB6CHQWHZW4TV</td>\n",
              "      <td>7508492919</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Kai</td>\n",
              "      <td>so the case came on time, i love the design. I...</td>\n",
              "      <td>Its okay</td>\n",
              "      <td>1391817600</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>True</td>\n",
              "      <td>02 4, 2014</td>\n",
              "      <td>A1M117A53LEI8</td>\n",
              "      <td>7508492919</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Sharon Williams</td>\n",
              "      <td>DON'T CARE FOR IT.  GAVE IT AS A GIFT AND THEY...</td>\n",
              "      <td>CASE</td>\n",
              "      <td>1391472000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>True</td>\n",
              "      <td>02 3, 2014</td>\n",
              "      <td>A272DUT8M88ZS8</td>\n",
              "      <td>7508492919</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Bella Rodriguez</td>\n",
              "      <td>I liked it because it was cute, but the studs ...</td>\n",
              "      <td>Cute!</td>\n",
              "      <td>1391385600</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1128432</th>\n",
              "      <td>4</td>\n",
              "      <td>True</td>\n",
              "      <td>12 22, 2016</td>\n",
              "      <td>A1QWMCG1FNEP3A</td>\n",
              "      <td>B01HJC7N4C</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Amazon Customer</td>\n",
              "      <td>Good for viewing. But doesn't have a button or...</td>\n",
              "      <td>Good</td>\n",
              "      <td>1482364800</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1128433</th>\n",
              "      <td>5</td>\n",
              "      <td>False</td>\n",
              "      <td>07 15, 2016</td>\n",
              "      <td>A3FOBEJ9UVUTR3</td>\n",
              "      <td>B01HJC7N4C</td>\n",
              "      <td>NaN</td>\n",
              "      <td>David Harlow</td>\n",
              "      <td>I was given the Rockrok 3D VR Glasses Headset ...</td>\n",
              "      <td>THE FUTURE IS NOW!!!!!!!</td>\n",
              "      <td>1468540800</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1128434</th>\n",
              "      <td>5</td>\n",
              "      <td>False</td>\n",
              "      <td>07 14, 2016</td>\n",
              "      <td>AMUEAMKB4E33M</td>\n",
              "      <td>B01HJC7N4C</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Tom D</td>\n",
              "      <td>Super Fun! The RockRoc 3d vr headset is waaaay...</td>\n",
              "      <td>Get more out of your smartphone .......</td>\n",
              "      <td>1468454400</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[https://images-na.ssl-images-amazon.com/image...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1128435</th>\n",
              "      <td>5</td>\n",
              "      <td>False</td>\n",
              "      <td>07 13, 2016</td>\n",
              "      <td>A2EV91MMOJ3IL4</td>\n",
              "      <td>B01HJC7N4C</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Timber12</td>\n",
              "      <td>Love it!\\n\\nI've had other VR glasses which al...</td>\n",
              "      <td>Join the VR fun train!</td>\n",
              "      <td>1468368000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1128436</th>\n",
              "      <td>5</td>\n",
              "      <td>True</td>\n",
              "      <td>05 11, 2017</td>\n",
              "      <td>ARKQD9Z1VPOV2</td>\n",
              "      <td>B01HJH9IN6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Malfacini</td>\n",
              "      <td>i love it</td>\n",
              "      <td>Five Stars</td>\n",
              "      <td>1494460800</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1128437 rows × 12 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         overall  ...                                              image\n",
              "0              5  ...                                                NaN\n",
              "1              5  ...                                                NaN\n",
              "2              3  ...                                                NaN\n",
              "3              2  ...                                                NaN\n",
              "4              4  ...                                                NaN\n",
              "...          ...  ...                                                ...\n",
              "1128432        4  ...                                                NaN\n",
              "1128433        5  ...                                                NaN\n",
              "1128434        5  ...  [https://images-na.ssl-images-amazon.com/image...\n",
              "1128435        5  ...                                                NaN\n",
              "1128436        5  ...                                                NaN\n",
              "\n",
              "[1128437 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ml-r0E7HthZQ",
        "colab_type": "text"
      },
      "source": [
        "I can potentially get sentiment analysis with the overall rating column aswell the review text.\n",
        "I can also label each review based on each sentiment\n",
        "title can contain positive/negative or netural information about review."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NIKvCe-wRvsF",
        "colab_type": "code",
        "outputId": "dfef7362-560f-4a13-e948-1e8815666374",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "data.overall.value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5    707038\n",
              "4    184431\n",
              "3     98254\n",
              "1     81539\n",
              "2     57175\n",
              "Name: overall, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I4g548m3qMZE",
        "colab_type": "code",
        "outputId": "f9732bf3-b884-4b1d-f8d4-c0967030f531",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "source": [
        "data.info()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1128437 entries, 0 to 1128436\n",
            "Data columns (total 12 columns):\n",
            " #   Column          Non-Null Count    Dtype \n",
            "---  ------          --------------    ----- \n",
            " 0   overall         1128437 non-null  int64 \n",
            " 1   verified        1128437 non-null  bool  \n",
            " 2   reviewTime      1128437 non-null  object\n",
            " 3   reviewerID      1128437 non-null  object\n",
            " 4   asin            1128437 non-null  object\n",
            " 5   style           605241 non-null   object\n",
            " 6   reviewerName    1128302 non-null  object\n",
            " 7   reviewText      1127672 non-null  object\n",
            " 8   summary         1127920 non-null  object\n",
            " 9   unixReviewTime  1128437 non-null  int64 \n",
            " 10  vote            92034 non-null    object\n",
            " 11  image           27107 non-null    object\n",
            "dtypes: bool(1), int64(2), object(9)\n",
            "memory usage: 95.8+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WNV3siiuuNkF",
        "colab_type": "text"
      },
      "source": [
        "Based on the information above:\n",
        "\n",
        "Dropping the style vote and image columns."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1erORz5oq2kY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = data.drop(['style', 'vote','image'], axis = 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CuMjvOGRuis7",
        "colab_type": "text"
      },
      "source": [
        "Before I explore the dataset I am going to split data into training set and test sets\n",
        "\n",
        "My aim is to finally train a sentiment analysis classifier\n",
        "\n",
        "Since the majority of reviews are positive (5 stars), we will need to do a stratified split on the reviews score to ensure that we don't train the classifier on imbalanced data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qlp5CQiJ6iHn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "split = StratifiedShuffleSplit(n_splits=5, test_size=0.2)\n",
        "for train_index, test_index in split.split(df, df[\"overall\"]): \n",
        "    strat_train = df.reindex(train_index)\n",
        "    strat_test = df.reindex(test_index)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bc44q25DvIVj",
        "colab_type": "text"
      },
      "source": [
        "Checking if the train or test sets were stratified proportionately in comparison to raw data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jAn5xJP565iM",
        "colab_type": "code",
        "outputId": "90bd000f-1e62-469d-af7d-f4516fa1aec9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(strat_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "902749"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5eEQb5L7YE-",
        "colab_type": "code",
        "outputId": "affcdc9f-93df-4b18-d7b1-5a6a7b86dc04",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "strat_train[\"overall\"].value_counts()/len(strat_train) # value_count() counts all the value"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5    0.626564\n",
              "4    0.163440\n",
              "3    0.087071\n",
              "1    0.072258\n",
              "2    0.050667\n",
              "Name: overall, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1MPsEwBC7f67",
        "colab_type": "code",
        "outputId": "453e7bc1-4113-4783-ecb5-6e7c5bed7313",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(strat_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "225688"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S7js-5ge7ghc",
        "colab_type": "code",
        "outputId": "57169e7b-7a5b-4ccd-ffc1-11e0756991fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "strat_test[\"overall\"].value_counts()/len(strat_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5    0.626564\n",
              "4    0.163438\n",
              "3    0.087072\n",
              "1    0.072259\n",
              "2    0.050667\n",
              "Name: overall, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RXqYlA8I7qLf",
        "colab_type": "code",
        "outputId": "3971f4b7-58bc-48f0-b243-41863ffcfd8d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        }
      },
      "source": [
        "details = strat_train.copy()\n",
        "details.head(2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>overall</th>\n",
              "      <th>verified</th>\n",
              "      <th>reviewTime</th>\n",
              "      <th>reviewerID</th>\n",
              "      <th>asin</th>\n",
              "      <th>reviewerName</th>\n",
              "      <th>reviewText</th>\n",
              "      <th>summary</th>\n",
              "      <th>unixReviewTime</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>649589</th>\n",
              "      <td>4</td>\n",
              "      <td>True</td>\n",
              "      <td>03 2, 2015</td>\n",
              "      <td>AN6M72QDDWRDI</td>\n",
              "      <td>B00S5PZIMW</td>\n",
              "      <td>Deitre Malory</td>\n",
              "      <td>very pleased</td>\n",
              "      <td>Four Stars</td>\n",
              "      <td>1425254400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>208918</th>\n",
              "      <td>4</td>\n",
              "      <td>True</td>\n",
              "      <td>10 2, 2013</td>\n",
              "      <td>AHO6LKSR001ZQ</td>\n",
              "      <td>B00BKWY6AW</td>\n",
              "      <td>Karin Stern</td>\n",
              "      <td>Saw this case demo'd on an online review and l...</td>\n",
              "      <td>Great case, especially for the price</td>\n",
              "      <td>1380672000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        overall  verified  ...                               summary unixReviewTime\n",
              "649589        4      True  ...                            Four Stars     1425254400\n",
              "208918        4      True  ...  Great case, especially for the price     1380672000\n",
              "\n",
              "[2 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wXHT8qUAve9J",
        "colab_type": "text"
      },
      "source": [
        "Segregate ratings from 1-5 into positive, neutral, and negative."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XcTrwxKZYvOV",
        "colab_type": "code",
        "outputId": "9b961198-4f7f-4821-a091-0e80084c91fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "def sentiments(overall):\n",
        "    if (overall == 5) or (overall == 4):\n",
        "        return \"Positive\"\n",
        "    elif overall == 3:\n",
        "        return \"Neutral\"\n",
        "    elif (overall == 2) or (overall == 1):\n",
        "        return \"Negative\"\n",
        "# Add sentiments to the data\n",
        "strat_train[\"Sentiment\"] = strat_train[\"overall\"].apply(sentiments)\n",
        "strat_test[\"Sentiment\"] = strat_test[\"overall\"].apply(sentiments)\n",
        "strat_train[\"Sentiment\"][:20]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "649589     Positive\n",
              "208918     Positive\n",
              "996414     Positive\n",
              "7420       Positive\n",
              "1090692    Positive\n",
              "255262     Positive\n",
              "515552     Positive\n",
              "1086853    Positive\n",
              "362674     Positive\n",
              "952464     Positive\n",
              "116881     Negative\n",
              "841421     Positive\n",
              "546658      Neutral\n",
              "201829     Positive\n",
              "431458     Positive\n",
              "224293     Positive\n",
              "427372     Positive\n",
              "724886     Positive\n",
              "1050266    Negative\n",
              "162732     Positive\n",
              "Name: Sentiment, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DxmygI6fZm35",
        "colab_type": "code",
        "outputId": "449b8e56-90c0-4a8c-97d0-ace67d2bcc8e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_train = strat_train[\"reviewText\"]\n",
        "X_train_targetSentiment = strat_train[\"Sentiment\"]\n",
        "X_test = strat_test[\"reviewText\"]\n",
        "X_test_targetSentiment = strat_test[\"Sentiment\"]\n",
        "print(len(X_train), len(X_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "902749 225688\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ImpGFLR_v10V",
        "colab_type": "text"
      },
      "source": [
        "Using CountVectorizer to performs:\n",
        "\n",
        "Text preprocessing:Tokenization (breaking sentences into words)\n",
        "\n",
        "Stopwords (filtering \"the\", \"are\", etc)\n",
        "\n",
        "Occurrence counting (builds a dictionary of features from integer indices with word occurrences)\n",
        "\n",
        "Feature Vector (converts the dictionary of text documents into a feature vector)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LoicL9giaTwm",
        "colab_type": "code",
        "outputId": "ca78c69a-14f0-4ec9-efc3-5409f29e1dd2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_train = X_train.fillna(' ')\n",
        "X_test = X_test.fillna(' ')\n",
        "X_train_targetSentiment = X_train_targetSentiment.fillna(' ')\n",
        "X_test_targetSentiment = X_test_targetSentiment.fillna(' ')\n",
        "\n",
        "# Text preprocessing and occurance counting\n",
        "from sklearn.feature_extraction.text import CountVectorizer \n",
        "count_vect = CountVectorizer()\n",
        "X_train_counts = count_vect.fit_transform(X_train) \n",
        "X_train_counts.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(902749, 118421)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hlATXGtEwH1s",
        "colab_type": "text"
      },
      "source": [
        "I see higher average count values on words that carry very little meaning, this will overshadow shorter documents that have lower average counts with same frequencies, as a result, we will use TfidfTransformer to reduce this redundancy:\n",
        "\n",
        "Term Frequencies (Tf) divides number of occurrences for each word by total number of words\n",
        "\n",
        "Term Frequencies times Inverse Document Frequency (Tfidf) downscales the weights of each word (assigns less value to unimportant stop words ie. \"the\", \"are\", etc)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PLBo0fiHab_n",
        "colab_type": "code",
        "outputId": "c4beaf3e-89b4-4160-babd-b6bf2db8a864",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "tfidf_transformer = TfidfTransformer(use_idf=False)\n",
        "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
        "X_train_tfidf.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(902749, 118421)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BvyBlffxwZtl",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "Logistic Regression Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ILavgO2RbGMS",
        "colab_type": "code",
        "outputId": "6375173c-90c2-4812-8ac2-dcffea119424",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        }
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "clf_logReg_pipe = Pipeline([(\"vect\", CountVectorizer()), \n",
        "                            (\"tfidf\", TfidfTransformer()), \n",
        "                            (\"clf_logReg\", LogisticRegression())])\n",
        "clf_logReg_pipe.fit(X_train, X_train_targetSentiment)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('vect',\n",
              "                 CountVectorizer(analyzer='word', binary=False,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
              "                                 input='content', lowercase=True, max_df=1.0,\n",
              "                                 max_features=None, min_df=1,\n",
              "                                 ngram_range=(1, 1), preprocessor=None,\n",
              "                                 stop_words=None, strip_accents=None,\n",
              "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                                 tokenizer=None, vocabulary=Non...\n",
              "                ('tfidf',\n",
              "                 TfidfTransformer(norm='l2', smooth_idf=True,\n",
              "                                  sublinear_tf=False, use_idf=True)),\n",
              "                ('clf_logReg',\n",
              "                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
              "                                    fit_intercept=True, intercept_scaling=1,\n",
              "                                    l1_ratio=None, max_iter=100,\n",
              "                                    multi_class='auto', n_jobs=None,\n",
              "                                    penalty='l2', random_state=None,\n",
              "                                    solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                                    warm_start=False))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ii81kova8dKY",
        "colab_type": "code",
        "outputId": "bbf83193-dbdd-4c51-afec-222460ab40b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import numpy as np\n",
        "predictedLogReg = clf_logReg_pipe.predict(X_test)\n",
        "np.mean(predictedLogReg == X_test_targetSentiment)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8645873949877707"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bOJmxd2CwcF6",
        "colab_type": "text"
      },
      "source": [
        "Support Vector Machine Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8SbLjYehc9OD",
        "colab_type": "code",
        "outputId": "05a144da-7e4a-45f5-8102-cb264d01026c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.pipeline import Pipeline\n",
        "clf_linearSVC_pipe = Pipeline([(\"vect\", CountVectorizer()), \n",
        "                               (\"tfidf\", TfidfTransformer()),\n",
        "                               (\"clf_linearSVC\", LinearSVC())])\n",
        "clf_linearSVC_pipe.fit(X_train, X_train_targetSentiment)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('vect',\n",
              "                 CountVectorizer(analyzer='word', binary=False,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
              "                                 input='content', lowercase=True, max_df=1.0,\n",
              "                                 max_features=None, min_df=1,\n",
              "                                 ngram_range=(1, 1), preprocessor=None,\n",
              "                                 stop_words=None, strip_accents=None,\n",
              "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                                 tokenizer=None, vocabulary=None)),\n",
              "                ('tfidf',\n",
              "                 TfidfTransformer(norm='l2', smooth_idf=True,\n",
              "                                  sublinear_tf=False, use_idf=True)),\n",
              "                ('clf_linearSVC',\n",
              "                 LinearSVC(C=1.0, class_weight=None, dual=True,\n",
              "                           fit_intercept=True, intercept_scaling=1,\n",
              "                           loss='squared_hinge', max_iter=1000,\n",
              "                           multi_class='ovr', penalty='l2', random_state=None,\n",
              "                           tol=0.0001, verbose=0))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aZsI1YiR8lq5",
        "colab_type": "code",
        "outputId": "0a20e85c-86db-4315-a7be-e2ce0669589a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import numpy as np\n",
        "predictedLinearSVC = clf_linearSVC_pipe.predict(X_test)\n",
        "np.mean(predictedLinearSVC == X_test_targetSentiment)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8638385736060402"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JgMHT8QAPDDB",
        "colab_type": "text"
      },
      "source": [
        "Support Vector Machine Regressor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ARjcS1JKPJLY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.svm import SVR\n",
        "svr_linear = SVR(kernel='linear',gamma='scale', C=1.0, epsilon=0.1)\n",
        "svr_linear.fit(X_train, X_train_targetSentiment)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T8lLPopHwfnT",
        "colab_type": "text"
      },
      "source": [
        "Multinominal Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ouLbAaoulHa",
        "colab_type": "code",
        "outputId": "d339eb35-5f72-4f01-e943-8d409340518c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "clf_multiNB_pipe = Pipeline([(\"vect\", CountVectorizer()), (\"tfidf\", TfidfTransformer()), (\"clf_nominalNB\", MultinomialNB())])\n",
        "clf_multiNB_pipe.fit(X_train, X_train_targetSentiment)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('vect',\n",
              "                 CountVectorizer(analyzer='word', binary=False,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
              "                                 input='content', lowercase=True, max_df=1.0,\n",
              "                                 max_features=None, min_df=1,\n",
              "                                 ngram_range=(1, 1), preprocessor=None,\n",
              "                                 stop_words=None, strip_accents=None,\n",
              "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                                 tokenizer=None, vocabulary=None)),\n",
              "                ('tfidf',\n",
              "                 TfidfTransformer(norm='l2', smooth_idf=True,\n",
              "                                  sublinear_tf=False, use_idf=True)),\n",
              "                ('clf_nominalNB',\n",
              "                 MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hRS9rl828qZ7",
        "colab_type": "code",
        "outputId": "2aac2ec5-989e-47b5-d139-af43d3e9b5f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import numpy as np\n",
        "predictedMultiNB = clf_multiNB_pipe.predict(X_test)\n",
        "np.mean(predictedMultiNB == X_test_targetSentiment)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.808616319875226"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UDWu2oFfwk-K",
        "colab_type": "text"
      },
      "source": [
        "I will the Support Vector Machine Classifier since it has the highest accuracy level. \n",
        "Now I will fine tune the Support Vector Machine model (Linear_SVC) to avoid any potential over-fitting."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oG2vU52Ow5PY",
        "colab_type": "text"
      },
      "source": [
        "Fine tuning the Support Vector Machine Classifier\n",
        "\n",
        "I will run a Grid Search of the best parameters on a grid of possible values, instead of tweaking the parameters of various components of the chain (ie. use_idf in tfidftransformer)and also run the grid search with LinearSVC classifier pipeline, parameters and cpu core maximization\n",
        "Then I will fit the grid search to our training data set and use final classifier (after fine-tuning) to test some arbitrary reviews"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hiLZWV_j-dMF",
        "colab_type": "code",
        "outputId": "9b07b364-c43d-40bd-88aa-25a2485f1b2c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "parameters = {'vect__ngram_range': [(1, 1), (1, 2)],    \n",
        "             'tfidf__use_idf': (True, False), \n",
        "             } \n",
        "gs_clf_LinearSVC_pipe = GridSearchCV(clf_linearSVC_pipe, parameters, n_jobs=-1)\n",
        "gs_clf_LinearSVC_pipe = gs_clf_LinearSVC_pipe.fit(X_train, X_train_targetSentiment)\n",
        "new_text = [\"The product is good.\", # positive\n",
        "            \"The product is ok.\", # neutral\n",
        "            \"The product is not good.\"] # negative\n",
        "\n",
        "X_train_targetSentiment[gs_clf_LinearSVC_pipe.predict(new_text)]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Positive    NaN\n",
              "Neutral     NaN\n",
              "Negative    NaN\n",
              "Name: Sentiment, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x1TbSYQGxTx6",
        "colab_type": "text"
      },
      "source": [
        "After testing some arbitrary reviews, it seems that my features is performing correctly with Positive, Neutral, Negative results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KmO-YTb6LASg",
        "colab_type": "code",
        "outputId": "a8fd254b-53d7-467d-fe7b-31da0f72d4b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "predictedGS_clf_LinearSVC_pipe = gs_clf_LinearSVC_pipe.predict(X_test)\n",
        "np.mean(predictedGS_clf_LinearSVC_pipe == X_test_targetSentiment)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8844776860090036"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BOSxK5QoxXFT",
        "colab_type": "text"
      },
      "source": [
        "Analyzing the best mean score of the grid search (classifier, parameters, CPU core)\n",
        "\n",
        "Analyzing the best estimator\n",
        "\n",
        "Analyzing the best parameter"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9vN465SbLEi9",
        "colab_type": "code",
        "outputId": "6ea35b34-4f09-4cf9-e415-5e36d44c3f7d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "for performance_analysis in (gs_clf_LinearSVC_pipe.best_score_, \n",
        "                             gs_clf_LinearSVC_pipe.best_estimator_, \n",
        "                             gs_clf_LinearSVC_pipe.best_params_):\n",
        "        print(performance_analysis)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8829043281924406\n",
            "Pipeline(memory=None,\n",
            "         steps=[('vect',\n",
            "                 CountVectorizer(analyzer='word', binary=False,\n",
            "                                 decode_error='strict',\n",
            "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
            "                                 input='content', lowercase=True, max_df=1.0,\n",
            "                                 max_features=None, min_df=1,\n",
            "                                 ngram_range=(1, 2), preprocessor=None,\n",
            "                                 stop_words=None, strip_accents=None,\n",
            "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
            "                                 tokenizer=None, vocabulary=None)),\n",
            "                ('tfidf',\n",
            "                 TfidfTransformer(norm='l2', smooth_idf=True,\n",
            "                                  sublinear_tf=False, use_idf=False)),\n",
            "                ('clf_linearSVC',\n",
            "                 LinearSVC(C=1.0, class_weight=None, dual=True,\n",
            "                           fit_intercept=True, intercept_scaling=1,\n",
            "                           loss='squared_hinge', max_iter=1000,\n",
            "                           multi_class='ovr', penalty='l2', random_state=None,\n",
            "                           tol=0.0001, verbose=0))],\n",
            "         verbose=False)\n",
            "{'tfidf__use_idf': False, 'vect__ngram_range': (1, 2)}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8mztMsfixy94",
        "colab_type": "text"
      },
      "source": [
        "Precision: determines how many objects selected were correct\n",
        "\n",
        "Recall: tells you how many of the objects that should have been selected were actually selected\n",
        "\n",
        "F1 score measures the weights of recall and precision (1 means precision and recall are equally important, 0 otherwise)\n",
        "\n",
        "Support is the number of occurrences of each class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-17h_zMLItd",
        "colab_type": "code",
        "outputId": "98c1911b-37da-47ae-8a49-eedb31911f66",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "print(classification_report(X_test_targetSentiment, predictedGS_clf_LinearSVC_pipe))\n",
        "print('Accuracy'. format(accuracy_score(X_test_targetSentiment, predictedGS_clf_LinearSVC_pipe)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Negative       0.76      0.77      0.76     27743\n",
            "     Neutral       0.53      0.20      0.29     19651\n",
            "    Positive       0.92      0.98      0.95    178294\n",
            "\n",
            "    accuracy                           0.88    225688\n",
            "   macro avg       0.74      0.65      0.67    225688\n",
            "weighted avg       0.86      0.88      0.87    225688\n",
            "\n",
            "Accuracy: 0.8844776860090036\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YHBdApwuLMYr",
        "colab_type": "code",
        "outputId": "9b7f450e-942c-4a1c-eba0-3674da9a9f5d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "from sklearn import metrics\n",
        "metrics.confusion_matrix(X_test_targetSentiment, predictedGS_clf_LinearSVC_pipe)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 21313,   1619,   4811],\n",
              "       [  4755,   3932,  10964],\n",
              "       [  2120,   1803, 174371]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2LWXGD7dx_V1",
        "colab_type": "text"
      },
      "source": [
        "Finally, the overall result here explains that the products in this dataset are generally positively rated."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "taoe_gveQzYu",
        "colab_type": "text"
      },
      "source": [
        "Reference: https://github.com/mick-zhang/Amazon-Reviews-using-Sentiment-Analysis/\n"
      ]
    }
  ]
}